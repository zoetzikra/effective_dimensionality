# Effective Dimensionality & Local Learning Coefficient Analysis for Adversarial Training

A comprehensive research framework for analyzing model complexity and learning dynamics in adversarial training through **Local Learning Coefficients (LLC)** and **Effective Dimensionality** measurements.

## ğŸ¯ Overview

This project provides a complete pipeline for understanding how adversarial training affects model complexity through two complementary measures:

1. **Local Learning Coefficient (LLC)** - A singularity-aware complexity measure using SGLD sampling
2. **Effective Dimensionality** - Hessian eigenvalue-based complexity analysis via Lanczos iteration

### Key Capabilities

- **ğŸ›¡ï¸ Adversarial Training Pipeline** - Complete MAIR-based training with multiple defense methods
- **ğŸ“Š LLC Measurement** - Advanced hyperparameter calibration and trajectory analysis
- **ğŸ” Effective Dimensionality Analysis** - Hessian eigenvalue computation and complexity tracking
- **âš”ï¸ Cross-Attack Analysis** - Compare LLC signatures across different attack types (Lâˆ, L2, L1)
- **ğŸ”¬ Comprehensive Evaluation** - Clean vs adversarial data comparison
- **ğŸ“ˆ Rich Visualizations** - Training dynamics, complexity evolution, and comparative plots
- **ğŸš€ HPC Integration** - SLURM job scripts for large-scale experiments

## ğŸ—ï¸ Project Structure

```
effective_dimensionality/
â”œâ”€â”€ ğŸ§  Core Analysis
â”‚   â”œâ”€â”€ llc_measurement.py              # LLC measurement with advanced calibration
â”‚   â”œâ”€â”€ llc_analysis_pipeline.py        # Comprehensive LLC analysis pipeline
â”‚   â”œâ”€â”€ effective_dimensionality_analysis.py # Hessian-based complexity analysis
â”‚   â”œâ”€â”€ cross_attack_llc_analysis.py    # Cross-attack LLC signature analysis
â”‚   â””â”€â”€ comprehensive_model_evaluation.py # Unified evaluation framework
â”‚
â”œâ”€â”€ ğŸ›¡ï¸ Adversarial Training
â”‚   â”œâ”€â”€ AT_replication_complete.py      # Complete adversarial training pipeline
â”‚   â”œâ”€â”€ AT_replication_single_model.py  # Single model training
â”‚   â”œâ”€â”€ mair_compatible_checkpoint_trainer.py # MAIR checkpoint integration
â”‚   â””â”€â”€ MAIR/                           # MAIR adversarial training framework
â”‚
â”œâ”€â”€ ğŸ“Š Visualization & Analysis
â”‚   â”œâ”€â”€ generate_comparison_plots.py    # Training dynamics visualization
â”‚   â”œâ”€â”€ create_cross_attack_plot.py     # Cross-attack analysis plots
â”‚   â”œâ”€â”€ compare_final_llc_values.py     # Final LLC comparison
â”‚   â””â”€â”€ fix_multi_epsilon_plot.py       # Multi-epsilon analysis plots
â”‚
â”œâ”€â”€ ğŸ”§ Utilities & Support
â”‚   â”œâ”€â”€ hess_vec_prod.py                # Hessian-vector products
â”‚   â”œâ”€â”€ utils.py                        # General utilities
â”‚   â”œâ”€â”€ model.py                        # Model definitions
â”‚   â””â”€â”€ inspect_checkpoint.py           # Checkpoint inspection
â”‚
â”œâ”€â”€ ğŸ’¼ Job Scripts & Workflows
â”‚   â”œâ”€â”€ run_*.job                       # SLURM job scripts
â”‚   â”œâ”€â”€ training_jobs/                  # Training job scripts
â”‚   â””â”€â”€ RunMethod_*.out                 # Job outputs and logs
â”‚
â”œâ”€â”€ ğŸ“ Data & Results
â”‚   â”œâ”€â”€ models/                         # Trained model checkpoints
â”‚   â”œâ”€â”€ llc_analysis/                   # LLC analysis results
â”‚   â”œâ”€â”€ eff_dim_analysis/              # Effective dimensionality results
â”‚   â”œâ”€â”€ comprehensive_evaluation/       # Evaluation results
â”‚   â””â”€â”€ data/                          # Dataset cache
â”‚
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md                       # This file
    â”œâ”€â”€ README_LLC.md                   # Detailed LLC documentation
    â”œâ”€â”€ CONFIGURATION_IMPROVEMENTS.md   # Configuration guide
    â””â”€â”€ requirements_llc.txt            # Python dependencies
```

## ğŸš€ Quick Start

### 1. Installation

```bash
# Clone the repository
git clone <repository_url>
cd effective_dimensionality

# Install dependencies
pip install -r requirements_llc.txt

# Install MAIR framework
cd MAIR
pip install -e .
cd ..

# Install devinterp for LLC measurement
pip install devinterp
```

### 2. Train Models

```bash
# Train a single model with adversarial training
python AT_replication_complete.py --model ResNet18 --method AT

# Train with Adversarial Weight Perturbation (AWP)
python AT_replication_complete.py --model ResNet18 --method AT --awp

# Run complete experiment suite
python AT_replication_complete.py --full-suite
```

### 3. Analyze LLC Trajectories

```bash
# Single model LLC analysis
python llc_analysis_pipeline.py --mode single \
    --model_path ./models/ResNet18_AT/best.pth \
    --model_name ResNet18 \
    --dataset CIFAR10 \
    --defense_method AT

# Trajectory analysis across training checkpoints
python llc_analysis_pipeline.py --mode trajectory \
    --checkpoint_dir ./models/ResNet18_AT/epoch_iter/ \
    --model_name ResNet18 \
    --dataset CIFAR10 \
    --defense_method AT
```

### 4. Effective Dimensionality Analysis

```bash
# Single model effective dimensionality
python effective_dimensionality_analysis.py --model ResNet18 --defense AT

# Compare multiple defense methods
python effective_dimensionality_analysis.py --compare --model ResNet18

# Batch analyze all models
python effective_dimensionality_analysis.py --batch
```

### 5. Cross-Attack Analysis

```bash
# Analyze LLC signatures across different attack types
python cross_attack_llc_analysis.py \
    --model_path ./models/LeNet_AT/best.pth \
    --model_name LeNet \
    --dataset MNIST \
    --calibration_path ./calibration_results.json \
    --checkpoint_dir ./models/LeNet_AT/epoch_iter/
```

## ğŸ›¡ï¸ Supported Defense Methods

| Method | Description | Architectures | Datasets |
|--------|-------------|---------------|----------|
| **Standard** | Standard training (no adversarial) | LeNet, VGG11, ResNet18 | MNIST, CIFAR10 |
| **AT** | Adversarial Training (Madry et al.) | LeNet, VGG11, ResNet18 | MNIST, CIFAR10 |
| **TRADES** | Trade-off between Robustness and Accuracy | LeNet, VGG11, ResNet18 | MNIST, CIFAR10 |
| **MART** | Misclassification Aware adveRsarial Training | ResNet18 | CIFAR10 |
| **AT + AWP** | AT with Adversarial Weight Perturbation | VGG11, ResNet18 | CIFAR10 |
| **TRADES + AWP** | TRADES with AWP | ResNet18 | CIFAR10 |

## ğŸ“Š Analysis Capabilities

### Local Learning Coefficient (LLC)
- **Advanced Hyperparameter Calibration** - Stability-based parameter selection
- **Trajectory Analysis** - Track complexity evolution during training
- **Clean vs Adversarial Comparison** - LLC on different data types
- **Cross-Attack Signatures** - Compare LLC across Lâˆ, L2, L1 attacks
- **Diagnostic Monitoring** - MALA acceptance rates, convergence analysis

### Effective Dimensionality
- **Hessian Eigenvalue Analysis** - Top eigenvalues via Lanczos iteration
- **Complexity Evolution** - Track effective dimensionality during training
- **Defense Method Comparison** - Compare complexity across training methods
- **Batch Processing** - Analyze multiple models simultaneously

### Comprehensive Evaluation
- **Training Dynamics** - Loss, accuracy, and robustness evolution
- **Model Comparison** - Side-by-side analysis of different approaches
- **Statistical Analysis** - Significance testing and confidence intervals
- **Rich Visualizations** - Publication-ready plots and figures

## ğŸ”¬ Research Applications

### 1. Training Dynamics Analysis
```bash
# Generate training dynamics plots with LLC and effective dimensionality
python generate_comparison_plots.py --mode training_llc \
    --model_dir ./models/ResNet18_AT \
    --experiment_dir ./llc_analysis/ResNet18_AT_results \
    --eff_dim_path ./eff_dim_analysis/ResNet18_AT_results.json
```

### 2. Defense Method Comparison
```bash
# Compare LLC across different defense methods
python llc_analysis_pipeline.py --mode compare \
    --config_file model_comparison_config.json \
    --dataset CIFAR10
```

### 3. Cross-Attack Analysis
```bash
# Test LLC signatures across attack types
python cross_attack_llc_analysis.py \
    --model_path ./models/ResNet18_AT/best.pth \
    --model_name ResNet18 \
    --calibration_path ./calibration_results.json
```

## ğŸ–¥ï¸ HPC Integration

The project includes comprehensive SLURM job scripts for HPC environments:

### Training Jobs
```bash
# Submit adversarial training job
sbatch training_jobs/run_mair_adv_training_resnet_AT.job

# Submit training with AWP
sbatch training_jobs/run_mair_adv_training_resnet_AT_awp.job
```

### Analysis Jobs
```bash
# Submit LLC analysis job
sbatch run_llc_analysis.job

# Submit effective dimensionality analysis
sbatch run_eff_dim_analysis.job

# Submit cross-attack analysis
sbatch run_cross_attack_analysis.job
```

## ğŸ“ˆ Example Workflows

### Workflow 1: Complete Model Analysis
```bash
# 1. Train model
python AT_replication_complete.py --model ResNet18 --method AT

# 2. Analyze LLC trajectory
python llc_analysis_pipeline.py --mode trajectory \
    --checkpoint_dir ./models/ResNet18_AT/epoch_iter/ \
    --model_name ResNet18

# 3. Analyze effective dimensionality
python effective_dimensionality_analysis.py --model ResNet18 --defense AT

# 4. Generate comparison plots
python generate_comparison_plots.py --mode training_llc \
    --model_dir ./models/ResNet18_AT \
    --experiment_dir ./llc_results \
    --eff_dim_path ./eff_dim_results.json
```

### Workflow 2: Defense Method Comparison
```bash
# 1. Train multiple models
python AT_replication_complete.py --model ResNet18 --method Standard
python AT_replication_complete.py --model ResNet18 --method AT
python AT_replication_complete.py --model ResNet18 --method TRADES

# 2. Compare LLC across methods
python llc_analysis_pipeline.py --mode compare \
    --config_file defense_comparison.json

# 3. Compare effective dimensionality
python effective_dimensionality_analysis.py --compare --model ResNet18
```

### Workflow 3: Cross-Attack Investigation
```bash
# 1. Train adversarially robust model
python AT_replication_complete.py --model LeNet --method AT

# 2. Run cross-attack LLC analysis
python cross_attack_llc_analysis.py \
    --model_path ./models/LeNet_AT/best.pth \
    --model_name LeNet \
    --calibration_path ./calibration_results.json

# 3. Create cross-attack visualization
python create_cross_attack_plot.py \
    --results_dir ./cross_attack_results \
    --model_name "LeNet (AT)"
```

## ğŸ“Š Output Structure

```
results/
â”œâ”€â”€ llc_analysis/
â”‚   â”œâ”€â”€ llc_analysis_YYYYMMDD_HHMMSS/
â”‚   â”‚   â”œâ”€â”€ ModelName_DefenseMethod_single/
â”‚   â”‚   â”‚   â”œâ”€â”€ calibration/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calibration_sweep.png
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ calibration_results.json
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ llc_calibration_detailed_results.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ diagnostics/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ loss_trace.png
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ mala_acceptance_trace.png
â”‚   â”‚   â”‚   â””â”€â”€ analysis_results.json
â”‚   â”‚   â””â”€â”€ ModelName_DefenseMethod_trajectory/
â”‚   â”‚       â”œâ”€â”€ llc_results/
â”‚   â”‚       â”‚   â”œâ”€â”€ llc_trajectory.png
â”‚   â”‚       â”‚   â””â”€â”€ checkpoint_*_llc_results.json
â”‚   â”‚       â””â”€â”€ trajectory_results.json
â”‚
â”œâ”€â”€ eff_dim_analysis/
â”‚   â”œâ”€â”€ batch_analysis_YYYYMMDD_HHMMSS/
â”‚   â”‚   â”œâ”€â”€ ModelName_analysis/
â”‚   â”‚   â”‚   â”œâ”€â”€ DefenseMethod_effective_dim.json
â”‚   â”‚   â”‚   â””â”€â”€ DefenseMethod_effective_dim_plot.png
â”‚   â”‚   â””â”€â”€ batch_analysis_summary.json
â”‚
â”œâ”€â”€ cross_attack_analysis/
â”‚   â”œâ”€â”€ cross_attack_llc_trajectories.json
â”‚   â”œâ”€â”€ cross_attack_comparison_plot.png
â”‚   â””â”€â”€ cross_attack_summary_report.txt
â”‚
â””â”€â”€ comprehensive_evaluation/
    â”œâ”€â”€ evaluation_YYYYMMDD_HHMMSS/
    â”‚   â”œâ”€â”€ adversarial_evaluation/
    â”‚   â”œâ”€â”€ llc_analysis/
    â”‚   â””â”€â”€ plots/
    â””â”€â”€ comparison_plots/
```

## ğŸ› ï¸ Configuration

### LLC Configuration
```python
from llc_measurement import LLCConfig

config = LLCConfig(
    epsilon=1e-4,          # SGLD step size
    gamma=100.0,           # Localization strength  
    num_chains=8,          # Number of SGLD chains
    num_draws=2000,        # Samples per chain
    batch_size=512,        # SGLD batch size
    data_type="clean",     # "clean", "adversarial", or "mixed"
)
```

### Model Configuration
```json
{
  "models": [
    ["./models/ResNet18_AT/best.pth", "ResNet18", "AT", "Adversarial Training"],
    ["./models/ResNet18_TRADES/best.pth", "ResNet18", "TRADES", "TRADES Defense"],
    ["./models/ResNet18_MART/best.pth", "ResNet18", "MART", "MART Defense"]
  ]
}
```

## ğŸ” Key Research Questions

This framework enables investigation of:

1. **How does adversarial training affect model complexity?**
   - Compare LLC trajectories across defense methods
   - Analyze effective dimensionality evolution

2. **Do different attack types leave distinct complexity signatures?**
   - Cross-attack LLC analysis across Lâˆ, L2, L1 norms
   - Attack-specific complexity patterns

3. **What are the training dynamics of robust models?**
   - LLC and effective dimensionality during training
   - Critical transitions and phase changes

4. **How do architectural choices impact robustness-complexity trade-offs?**
   - Compare LeNet, VGG11, ResNet18 across defense methods
   - Architecture-specific complexity patterns

## ğŸ“š Documentation

- **[README_LLC.md](README_LLC.md)** - Detailed LLC measurement documentation
- **[CONFIGURATION_IMPROVEMENTS.md](CONFIGURATION_IMPROVEMENTS.md)** - Configuration and setup guide
- **[MAIR/README.md](MAIR/README.md)** - MAIR framework documentation

## ğŸ¤ Citation

If you use this framework in your research, please cite:

```bibtex
@misc{effective_dimensionality_adversarial,
  title={Effective Dimensionality and Local Learning Coefficient Analysis for Adversarial Training},
  author={[Your Name]},
  year={2024},
  note={Research framework for analyzing model complexity in adversarial training}
}
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ†˜ Support

For questions, issues, or contributions:
1. Check existing documentation in `README_LLC.md`
2. Review configuration guide in `CONFIGURATION_IMPROVEMENTS.md`
3. Examine example job scripts in `training_jobs/`
4. Open an issue with detailed information about your setup and error

---
